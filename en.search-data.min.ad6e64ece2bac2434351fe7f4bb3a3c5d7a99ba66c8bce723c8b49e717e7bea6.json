[{"id":0,"href":"/posts/lesson-1---an-introduction-to-ai/","title":"Lesson 1- An introduction to AI","section":"Lessons","content":"\rAn introduction to AI\r#\rArtificial intelligence can be found anywhere, both on the internet or in the devices you use such as YouTube recommendations or a self-braking car.\nWhat is AI?\r#\rArtificial intelligence is an algorithm that can learn patterns and make predictions on a certain topic. AI is used with computer science to solve real world problems. AI can also be used to help humans with their tasks and that is called augmented reality, such as a navigation system or a text reader for the blind. AI can also be used to mimic human intelligence and that is called artificial intelligence, such as diagnosing illnesses or recognising faces. The AI does this by being very good at guessing, this means that the AI has practised many, many times in the past and it learns from what it has done wrong until it minimises the error it has when guessing or predicting.\nHistory of AI\r#\rDespite the boom in AI interest in the past years, AI has existed since the 1940s. Where Alan Turing came up with the Turing test to see if machines could “think”. In the Turing test, a person talks to a human and a machine, if the person cannot distinguish between machine and human then the machine has passed the test.\nThe field of AI officially began in 1956 in a conference at Dartmouth, where scientists first coined the term “artificial intelligence”. They believed every feature of intelligence could be described so specifically that a machine could simulate it.One of the earliest demonstrations of AI is through ELIZA, it simulates the behaviour of a therapist and was created in 1966. However, there would be a period in AI history named the “AI winter”, this was a period with budget cuts and no breakthrough. This was due to the lack of computational power and data for any AI development. Later in 1986, this period ended with the resurgence of neural networks and back propagation in multiple layers. This led to the rise of machine learning which uses these neural networks to learn patterns in data. Later in the 21st century, with a much higher processing power, AI has achieved incredible progress through massive breakthroughs in deep learning and LLMs leading to things like ChatGPT for example.\nAI ethics\r#\rAI ethics in this case doesn’t just refer to morals of AI, it also refers to bias and fairness of AI. When AI is used to help humans in their activities, it can influence their decision making which is an issue if the AI isn’t fair. For example, AI could prioritise certain qualities when filtering job applications leading to discrimination. Developing AI systems like COMPAS which detect recidivists has caused controversy as it has identified racial groups as more or less likely to commit a crime.\nAnother issue is accountability; the legal repercussions of AI crimes are still in a grey area (though there have been major legal changes), an example of this could be, if a self-driving car commits a crime, should the manufacturer or the owner be accountable, or neither? One other major ethical concern is the data used in AI, when AI is trained it is using massive amounts of data taken from the internet which may lack true consent from people accessing the internet as it is written in a large TOS document. An example would be whether or not big tech companies taking user data to create AI controlled ads ethical? Furthermore, ever since generative AI has been popularised there has been a rise in the amount of misinformation or propaganda spread in the internet as well as AI faking as real people, since some laws regarding AI had not been fully clarified, these unethical practices have often unpunished, so it is important to use AI for ethical purposes.\nLastly, a concern amongst many people is using AI to replace workers. Though it may be true AI can replace some human functions, it is a debate whether or not AI could or should be used to replace jobs.\nReferences\r#\rhttps://www.ibm.com/topics/artificial-intelligence https://braidr.ai/augmented-vs-artificial-intelligence-whats-the-difference Further reading\r#\rhttps://students.yourlearning.ibm.com/activity/PLAN-CC702B39D429 "},{"id":1,"href":"/posts/lesson-2---types-of-ai/","title":"Lesson 2 - Types of AI","section":"Lessons","content":"\rTypes of AI\r#\rNarrow, broad, and general AI\r#\rA way to categorise AI is by the number of different tasks it can accomplish. The simplest of AI started from narrow AI which performs a few specific tasks (examples are virtual assistants/ Siri, image classification, recommendation like YouTube). Expanding from narrow AI, is broad AI, it has a large range of tasks it can accomplish. The next level of AI is general AI which performs human-like functions and has the ability to learn like humans can. This is currently theoretical, however tasks AI can do are still expanding and our technology is in the broad AI section. In the far future, AI may also develop further than humans (super AI). Supervised and un-supervised learning\r#\rAnother way to categorise AI is the different ways it operates. The most popular category is machine learning which is where AI is most effective. There are also other categories such as rule based systems which include expert systems. Within machine learning there are multiple categories. Supervised learning is when you train an algorithm using labelled data such as an image with a description attached to it. Unsupervised learning is when you train an algorithm using unlabelled data, the AI will find patterns within the data and can categorise them based on these patterns. Semi-supervised learning also exists which uses small groups of labelled data and large amount of unlabelled data. Self-supervised learning is very similar to unsupervised learning as it uses unlabelled data, however, it can be used in tasks that typically require supervised learning. Since labelling all the data is very time consuming, the SSL infers “labels” from its pre-existing trained knowledge. Reinforcement learning is an algorithm that is in an environment and learns from rewards or penalties based on their actions. Deep learning is when an algorithm uses many layers of neural networks to model highly complex data and can be applied in many contexts. Transfer learning is when an algorithm is already trained for a specific task but it can be fine tuned (trained in very small details) to adapt it for a different task.\nComplex AI models\r#\rThere are multiple types of AI models that use these concepts and combine them. Examples are classification, predictive or generative models. 2 very popular uses of these types are Large Language Models (LLMs) and Natural Language Processing (NLPs). NLPs are a type of model designed to understand and can interpret the language, this allows the model to perform multiple tasks such as language translation, sentiment analysis, language translation etc (though not multiple at once). It is trained from scratch to a specific task and its algorithm structure is different. LLMs are a type of model designed to understand and generate human language. It is adapted from NLPs. It can learn patterns, contexts and relationships in a language. LLMs typically uses deep learning and self-supervised learning as it uses large amounts of labelled data. It is also fine tuned to specific tasks most times.\nReferences\r#\rhttps://www.ibm.com/think/topics/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks https://www.geeksforgeeks.org/nlp-vs-llm/ Further reading\r#\rhttps://www.youtube.com/watch?v=zjkBMFhNj_g\u0026t=2674s "},{"id":2,"href":"/posts/lesson-3---neural-networks/","title":"Lesson 3 - Neural networks","section":"Lessons","content":"\rNeural networks\r#\rA neural network is one of the main building blocks in any artificial intelligence model. A neural network can take input data and output a probability of an output through mathematical functions.\nLayers\r#\rA neural network is made up of nodes. Each node can hold a value, typically between 0 and 1. Multiple nodes can make up a layer. The network will have 1 input layer and 1 output layer. Between these can be as many layers as you want, these in between layers are called hidden layers.\nForward propagation\r#\rWhen values from 1 layer is \u0026ldquo;propagated\u0026rdquo; to the next layer, the following happens:\nBetween each node in one layer to the next there is a weight. When one node is connected to another node in the next layer and the value is propagated forward, the current value is multiplied by the weight. Since every node between each layer is collected, the value of the next layer is simply the sum of all the weighted values of the previous layer. However, since we want our values to be between certain values, we can apply an activation function to the result. The activation function will squash every single possible number into a number between the desired range. For example, a sigmoid function will squash all the numbers between 0 and 1, the more negative a value is (such as -9999999) the closer to 0 the result of the function will be and vice versa. Bias\r#\rFor each layer, it is very common to have 1 bias value attached to the layer. This bias value is not derived from the propagation of the last layer but will be added into the sum of products into the next layer. The purpose for a bias value is to allow the model to capture more complex patterns.\nLoss and back propagation\r#\rOnce all the input values have been propagated through the model and the output values are found, the output values are compared to the label of the data. This comparison uses a loss function and it takes all the output values and the label and calculates a value to show how good or bad the output was. The loss function can take many forms such as taking the sum of all the absolute values of the difference between output and label, or you can take the sum of all the squared values of the difference. The loss function mostly depends on what the AI is being used for.\nAfter the loss value is calculated a process called back-propagation is started. Back-propagation uses calculus to find how much each of the weights and biases should be changed by compared to the loss value. Each of these calculated values are multiplied by the learning rate of the model and subtracted from each respective weights and biases.\nThe process of forward and backward propagation is done many times with the training data, the entire process is called gradient descent.\nReferences\r#\rhttps://www.youtube.com/watch?v=aircAruvnKk\u0026list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi https://www.ibm.com/topics/neural-networks Further reading\r#\rhttps://www.youtube.com/watch?v=VMj-3S1tku0 "},{"id":3,"href":"/posts/lesson-4---mnist-neural-network/","title":"Lesson 4 - MNIST neural network","section":"Lessons","content":"\rMaking your first neural network from scratch\r#\rFor the first model, we will be making a model that can recognise hand written numbers using the MNIST dataset.\nDesigning the model\r#\rFirstly, the MNIST database contains 70000 handwritten numbers in a grey-scale 28 x 28 bitmap image. The database will have a 2-D array containing the pixels each with a value between 0 to 255 on the grey-scale and a seperate array of data with the labels. This means there are 784 pixels in total per input data, therefore we will have 784 input nodes.\nNext, we will have 1 hidden layer for simplicity\u0026rsquo;s sake, this layer will have 40 nodes. Then we will have an output layer of 10 nodes. Each output node corresponding to a digit from 0 to 10.\nInitialisation\r#\rFirstly, we will fetch the data from the MNIST data base, we will assign the bitmap images to X and X_test, the labels as Y and Y_test. Initialising weights and biases; the weights between input and layer 2 will be names W1 and the size [40, 784], W2 for layer 2 and output layer will have a size of [10, 40]. We will also have a bias for the input layer and layer 2 named B1 and B2 with size [1, 40] and [1, 10] respectively. Forward propagation\r#\rWhen propagating from the input layer to the second layer we will take the dot product of X and W1 then add it to B1 to obtain Z1. The dot product takes every single bitmap image and multiplies each of them by our weight. Then we need to put Z1 through the activation function. For this model, we will use a sigmoid curve which is the function f(x) = 1/(1-e^-x). The result is A1 which is our second layer. We then take the dot product of A1 and W2 then add to B2 to obtain our output layer which is called Z2. We can then put Z2 through an activation function called softmax function. A softmax function takes a set of numbers and changes them to a probability based on how high each of the numbers were. Backward propagation\r#\rThis section can be skipped if you don\u0026rsquo;t understand calculus and the chain rule.\nFirstly, we calculate the differentiated value of Z2 or dZ2 which is dZ2 = A2 - one_hot(Y). one_hot(Y) means we are creating an array where all the values are 0 and the index of Y is 1. However, we need to divide dZ2 by the size of Y as we will be summing dZ2 for our bias. Next we differentiate W2 in terms of Z2 so we get A1, then applying the chain rule to get dW2 in terms of the loss, we multiply with dZ2. So we get dW2 = dZ2 x A1 When diffrentiating B2 in terms of Z2 we get 1, so applying the chain rule again to get dB2 in terms of the loss, we get dB2 = sum of Z2. To differentiate A1 in terms of Z2 we get W2, applying the chain rule to get dA1 in terms of the loss, we multiple W2 with dZ2. So we get dA1 = W2 x dZ2. Next we need to find the derivative of Z1, since A1 = sigmoid(Z1), we need to find the derivative of the sigmoid function which is f(x) x (1-f(x)) where f(x) is the sigmoid function. Let deriv_sigmoid(x) be the derivative of f(x). Then to find dZ1 we use the chain rule and get dZ1 = dA1 x deriv_sigmoid(Z1). Similar to step 2 and 3, we get dW1 = X * dZ1 and dB1 = sum of dZ1. Gradient descent\r#\rIn gradient descent there are 4 main steps:\nForward propagation. Backward propagation Update parameters (weights and biases). For this we take our original weights and biases then subtract by the respective derivatives multiplied by the learning rate. Track our accuracy on both train and test data. These 4 steps will looped a certain amount of time until the model is accurate enough to be used. Coding\r#\rThis code will be done in google colab.\nInitialisation\r#\rpath = \u0026#39;/tmp\u0026#39; def fetch(url): #This code can be ignored, it is just fetching data from a online file fp = os.path.join(path, hashlib.md5(url.encode(\u0026#39;utf-8\u0026#39;)).hexdigest()) if os.path.isfile(fp): with open(fp, \u0026#34;rb\u0026#34;) as f: data = f.read() else: with open(fp, \u0026#34;wb\u0026#34;) as f: data = requests.get(url).content f.write(data) return np.frombuffer(gzip.decompress(data), dtype=np.uint8).copy() X = fetch(\u0026#34;https://github.com/sunsided/mnist/raw/master/train-images-idx3-ubyte.gz\u0026#34;)[0x10:].reshape((-1, 28*28)).T #shaping data into a 2d array of size [x, 784], x is whatever number to make the data fit (60000). Then .T is to transpose the data from rows to columns and vice versa. This makes the data easier to work with. Y = fetch(\u0026#34;https://github.com/sunsided/mnist/raw/master/train-labels-idx1-ubyte.gz\u0026#34;)[8:].T.astype(\u0026#39;int\u0026#39;) #fetching labels, transpose and change to int data type X_test = fetch(\u0026#34;https://github.com/sunsided/mnist/raw/master/t10k-images-idx3-ubyte.gz\u0026#34;)[0x10:].reshape((-1, 28*28)).T Y_test = fetch(\u0026#34;https://github.com/sunsided/mnist/raw/master/t10k-labels-idx1-ubyte.gz\u0026#34;)[8:].T.astype(\u0026#39;int\u0026#39;) X = X / 255.0 # since data is between 0 and 255, we divide it by 255 to have the values between 0 and 1, this is called data normalisation. X_test = X_test / 255.0 def init_params(): # Initialiing all weights and parameters as a random number between -0.5 and 0.5 (data type double is just a float number that can have more significant figures) W1 = (np.random.rand(40, 784) - 0.5).astype(\u0026#39;double\u0026#39;) b1 = (np.random.rand(40, 1) - 0.5).astype(\u0026#39;double\u0026#39;) W2 = (np.random.rand(10, 40) - 0.5).astype(\u0026#39;double\u0026#39;) b2 = (np.random.rand(10, 1) - 0.5).astype(\u0026#39;double\u0026#39;) return W1, b1, W2, b2 Forward propagation\r#\rdef sigmoid(Z): #Activation function is to increase complexity and make the model non-linear, it also compresses all values to between 0 and 1 return 1/(1+np.exp(-Z)) def softmax(Z): #Softmax function reduces all numbers in an array to a probability between 0 and 1, sum of all elements should be 1 exp_element=np.exp(Z-Z.max()) return exp_element/np.sum(exp_element,axis=0) def forward_prop(W1, b1, W2, b2, X): #forward propagation Z1 = W1.dot(X) + b1 A1 = sigmoid(Z1) Z2 = W2.dot(A1) + b2 A2 = softmax(Z2) return Z1, A1, Z2, A2 Backward propagation\r#\rdef deriv_sigmoid(Z): return sigmoid(Z)*(1-sigmoid(Z)) #Derivative of the sigmoid function def back_prop(Z1, A1, Z2, A2, W1, W2, X, Y): #Back propagation, calculus dZ2 = (A2 - one_hot(Y))/Y.size dW2 = dZ2.dot(A1.T) db2 = np.sum(dZ2, axis = 1, keepdims = True) dA1 = W2.T.dot(dZ2) dZ1 = dA1 * deriv_sigmoid(Z1) dW1 = dZ1.dot(X.T) db1 = np.sum(dZ1, axis = 1, keepdims = True) return dW1, db1, dW2, db2 #These values tell how much each weight and bias has to be adjusted by def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, lr): #Update parameters, lr is the learning rate W1 = W1 - lr * dW1 b1 = b1 - lr * db1 W2 = W2 - lr * dW2 b2 = b2 - lr * db2 return W1, b1, W2, b2 Gradient descent\r#\rdef get_predictions(A2): #Gives an output prediction return np.argmax(A2, 0) def get_accuracy(predictions, Y): #Calculates accuracy based on all predictions and all lables return np.sum(predictions == Y) / Y.size def gradient_descent(X, Y, X_test, Y_test, lr, epochs, accuracies, test_accuracies, W1 = [], b1 = [], W2 = [], b2 = []): #Training the model for i in range(epochs): Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X) #forward propagation dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W1, W2, X, Y) #back propagation W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, lr) #update weights and biases predictions = get_predictions(A2) accuracies.append(get_accuracy(predictions, Y)) #Keep track of accuracy whilst training if i % 50 == 0: print(\u0026#34;Iteration: \u0026#34;, i) print(get_accuracy(predictions, Y)) #prints accuracy whilst training every 50 loops return W1, b1, W2, b2, A2, accuracies, test_accuracies accuracies = [] test_accuracies = [] W1, b1, W2, b2, A2, accuracies, test_accuracies = gradient_descent(X, Y, X_test, Y_test, 0.70, 200, accuracies, test_accuracies) Testing our model\r#\rdef make_predictions(X, W1, b1, W2, b2): #Get prediction based on a dataset _, _, _, A2 = forward_prop(W1, b1, W2, b2, X) predictions = get_predictions(A2) return predictions def test_prediction(index, W1, b1, W2, b2): #Get prediction based on 1 image from test dataset as well as plot image current_image = X_test[:, index, None] prediction = make_predictions(X_test[:, index, None], W1, b1, W2, b2) label = Y_test[index] print(\u0026#34;Prediction: \u0026#34;, prediction) print(\u0026#34;Label: \u0026#34;, label) current_image = current_image.reshape((28, 28)) * 255 plt.gray() plt.imshow(current_image, interpolation=\u0026#39;nearest\u0026#39;) plt.show() predictions = make_predictions(X_test, W1, b1, W2, b2) #Get accuracy from the test/ validation data test_accuracy = np.sum(predictions == Y_test) * 100 / Y_test.size print(\u0026#34;Accuracy = \u0026#34;, test_accuracy ,\u0026#34;%\u0026#34;) test_prediction(93, W1, b1, W2, b2) # Test from test image dataset from skimage.draw import line_aa img = np.zeros((14, 14), dtype=np.uint8) rr, cc, val = line_aa(4, 4, 2, 6) img[rr, cc] = val * 255 rr, cc, val = line_aa(2, 6, 4, 8) img[rr, cc] = val * 255 rr, cc, val = line_aa(4, 8, 10, 4) img[rr, cc] = val * 255 rr, cc, val = line_aa(10, 4, 10, 8) img[rr, cc] = val * 255 n_test = np.zeros((28, 28)) for i in range(13): for j in range(13): n_test[2*i][2*j] = img[i][j] n_test[2*i+1][2*j] = img[i][j] n_test[2*i][2*j+1] = img[i][j] n_test[2*i+1][2*j+1] = img[i][j] n_test = n_test/255 n_test = n_test.reshape(-1, 1) imshow(n_test.reshape(28,28)) prediction2 = make_predictions(n_test, W1, b1, W2, b2) print(prediction2) n = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 8, 7, 3, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 7, 2, 7, 8, 5, 0, 0, 0, 0, 0], [0, 0, 0, 9, 4, 0, 0, 2, 8, 2, 0, 0, 0, 0], [0, 0, 3, 6, 0, 0, 0, 0, 9, 2, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 8, 2, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 8, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 3, 8, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 7, 7, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 7, 6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 7, 8, 9, 7, 7, 7, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] n_test = np.zeros((28, 28)) for i in range(13): for j in range(13): n_test[2*i][2*j] = n[i][j] n_test[2*i+1][2*j] = n[i][j] n_test[2*i][2*j+1] = n[i][j] n_test[2*i+1][2*j+1] = n[i][j] n_test = n_test/10 n_test = n_test.reshape(-1, 1) imshow(n_test.reshape(28,28)) prediction2 = make_predictions(n_test, W1, b1, W2, b2) print(prediction2) Exercises\r#\rOnce the code is completed, here are some challenges you could do:\nKeep track of the test accuracy as the model is being trained. Try different things to increase accuracy as high as possible Are there any other different activation or loss functions you could use? References\r#\rhttps://www.youtube.com/watch?v=w8yWXqWQYmU\u0026t=532s https://www.geeksforgeeks.org/ml-one-hot-encoding/ https://davidbieber.com/snippets/2020-12-12-derivative-of-softmax-and-the-softmax-cross-entropy-loss https://github.com/sunsided/mnist Further reading\r#\rhttps://www.ibm.com/topics/overfitting "}]